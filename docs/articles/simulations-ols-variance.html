<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Simulations - OLS and Variance • estimatr</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../">estimatr</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/getting-started.html">Getting Started</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Technical Notes
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/technical-notes.html">Mathematical Notes</a>
    </li>
    <li>
      <a href="../articles/benchmarking-estimatr.html">Simulations - Speed Comparisons</a>
    </li>
    <li>
      <a href="../articles/simulations-ols-variance.html">Simulations - OLS and Variance</a>
    </li>
  </ul>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="http://discuss.declaredesign.org">Ask for Help</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Packages
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="http://declaredesign.org">DeclareDesign</a>
    </li>
    <li>
      <a href="http://randomizr.declaredesign.org">randomizr</a>
    </li>
    <li>
      <a href="http://fabricatr.declaredesign.org">fabricatr</a>
    </li>
    <li>
      <a href="http://estimatr.declaredesign.org">estimatr</a>
    </li>
  </ul>
</li>
<li>
  <a href="http://declaredesign.org">DeclareDesign home</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a></a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Simulations - OLS and Variance</h1>
                        <h4 class="author">Luke Sonnet</h4>
            
          </div>

    
    
<div class="contents">
<p>This document exposes the properties of different variance estimators using <a href="declaredesign.org"><code>DeclareDesign</code></a> and <a href="estimatr.declaredesign.org"><code>estimatr</code></a>. More details about the variance estimators with references can be found in the <a href="http://estimatr.declaredesign.org/articles/technical-notes.html">technical notes</a>.</p>
<div id="homoskedastic-errors-and-fixed-covariates" class="section level2">
<h2 class="hasAnchor">
<a href="#homoskedastic-errors-and-fixed-covariates" class="anchor"></a>Homoskedastic errors and fixed covariates</h2>
<p>Under simple conditions with homoskedasticity (i.e., all errors are drawn from a distribution with the same variance), the classical estimator of the variance of OLS should be unbiased. In this section I demonstrate this to be true using <a href="declaredesign.org"><code>DeclareDesign</code></a> and <a href="estimatr.declaredesign.org"><code>estimatr</code></a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(DeclareDesign)
<span class="kw">library</span>(ggplot2)</code></pre></div>
<p>First, let’s take a simple set up:</p>
<p><span class="math display">\[
\begin{aligned}
\mathbf{y} &amp;= \mathbf{X}\beta + \epsilon, \\
\epsilon_i &amp;\overset{i.i.d.}{\sim} N(0, \sigma^2).
\end{aligned}
\]</span></p>
<p>For our simulation, let’s have a constant and one covariate, so that <span class="math inline">\(\mathbf{X} = [\mathbf{1}, \mathbf{x_1}]\)</span>, where <span class="math inline">\(\mathbf{x_1}\)</span> is a column vector of a covariate drawn from a standard normal distribution. Let’s also assume that are covariates are fixed, rather than stochastic. Let’s draw the data we will use.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">41</span>)
dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> <span class="kw">rnorm</span>(<span class="dv">50</span>))</code></pre></div>
<p>The function</p>
<p><span class="math display">\[
\epsilon_i \overset{i.i.d.}{\sim} N(0, \sigma^2),
\]</span> encodes the assumption of homoskedaticity. Because of these homoskedastic errors, we know that the true variance of the coefficients with fixed covariates is</p>
<p><span class="math display">\[
\mathbb{V}[\widehat{\beta}] = \sigma^2 (\mathbf{X}^\top \mathbf{X})^{-1},
\]</span></p>
<p>where I hide conditioning on <span class="math inline">\(\mathbf{X}\)</span> for simplicity.</p>
<p>Let’s compute the true variance for our dataset.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">sigmasq &lt;-<span class="st"> </span><span class="dv">4</span>
<span class="co"># Build the X matrix with intercept</span>
Xmat &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="dv">1</span>, dat<span class="op">$</span>x)
<span class="co"># Invert XtX</span>
XtX_inv &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(Xmat))
<span class="co"># Get full variance covariance matrix</span>
true_var_cov_mat &lt;-<span class="st"> </span>sigmasq <span class="op">*</span><span class="st"> </span>XtX_inv</code></pre></div>
<p>But for this example, we are only going to focus on the variance for the covariate, not the intercept, so let’s store that variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">true_varb &lt;-<span class="st"> </span>true_var_cov_mat[<span class="dv">2</span>, <span class="dv">2</span>]
true_varb</code></pre></div>
<pre><code>## [1] 0.07831866</code></pre>
<p>Now, using <a href="declaredesign.org"><code>DeclareDesign</code></a>, let’s specify the rest of the data generating process (DGP). Let’s set <span class="math inline">\(\beta = [0, 1]^\top\)</span>, so that the true DGP is <span class="math inline">\(\mathbf{y} = \mathbf{x_1} + \epsilon\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">simp_pop &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_population">declare_population</a></span>(
  <span class="dt">epsilon =</span> <span class="kw">rnorm</span>(N, <span class="dt">sd =</span> <span class="dv">2</span>),
  <span class="dt">y =</span> x <span class="op">+</span><span class="st"> </span>epsilon
)</code></pre></div>
<p>Now let’s tell DeclareDesign that our target, our estimand, is the true variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">varb_estimand &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_estimand">declare_estimand</a></span>(<span class="dt">true_varb =</span> true_varb)</code></pre></div>
<p>Our estimator for this estimand will be the classical OLS variance estimator, which we know should be unbiased:</p>
<p><span class="math display">\[
\widehat{\mathbb{V}[\widehat{\beta}]} = \frac{\mathbf{e}^\top\mathbf{e}}{N - K} (\mathbf{X}^\top \mathbf{X})^{-1},
\]</span></p>
<p>where the residuals <span class="math inline">\(\mathbf{e} = \mathbf{y} - \mathbf{X}\widehat{\beta}\)</span>, <span class="math inline">\(N\)</span> is the number of observations, and <span class="math inline">\(K\)</span> is the number of regressors—two in our case. We can easily get this estimate of the variance by squaring the standard error we get out from <code>lm_robust</code> in <a href="estimatr.declaredesign.org"><code>estimatr</code></a>. Let’s tell <a href="declaredesign.org"><code>DeclareDesign</code></a> to use that estimator and get the coefficient on the <span class="math inline">\(\mathbf{x}_1\)</span> variable.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmc &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_estimator">declare_estimator</a></span>(
  y <span class="op">~</span><span class="st"> </span>x,
  <span class="dt">model =</span> estimatr<span class="op">::</span>lm_robust, 
  <span class="dt">se_type =</span> <span class="st">"classical"</span>,
  <span class="dt">estimand =</span> varb_estimand,
  <span class="dt">coefficient_name =</span> <span class="st">"x"</span>
)</code></pre></div>
<p>Now, we want to test for a few results using Monte Carlo simulation. Our main goal is to show that our estimated variance is unbiased for the true variance (our estimand). We can do this by comparing the mean of our estimated variances to the true variance. We can also show that the standard error of our coefficient estimate is the same as the standard deviation of the sampling distribution as our coefficient and that the coverage of our 95 percent confidence intervals is indeed 95 percent.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># First declare all the steps of our design, starting with our fixed data</span>
classical_design &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_design">declare_design</a></span>(
  dat,
  simp_pop,
  varb_estimand,
  lmc
)

<span class="co"># Declare a set of diagnosands that help us check if </span>
<span class="co"># we have unbiasedness</span>
my_diagnosands &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_diagnosands">declare_diagnosands</a></span>(
  <span class="st">`</span><span class="dt">Bias of Estimated Variance</span><span class="st">`</span> =<span class="st"> </span><span class="kw">mean</span>(se<span class="op">^</span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span>estimand),
  <span class="st">`</span><span class="dt">Bias of Standard Error</span><span class="st">`</span> =<span class="st"> </span><span class="kw">mean</span>(se <span class="op">-</span><span class="st"> </span><span class="kw">sd</span>(est)),
  <span class="st">`</span><span class="dt">Coverage Rate</span><span class="st">`</span> =<span class="st"> </span><span class="kw">mean</span>(<span class="dv">1</span> <span class="op">&lt;=</span><span class="st"> </span>ci_upper <span class="op">&amp;</span><span class="st"> </span><span class="dv">1</span> <span class="op">&gt;=</span><span class="st"> </span>ci_lower),
  <span class="st">`</span><span class="dt">Mean of Estimated Variance</span><span class="st">`</span> =<span class="st"> </span><span class="kw">mean</span>(se<span class="op">^</span><span class="dv">2</span>),
  <span class="st">`</span><span class="dt">True Variance</span><span class="st">`</span> =<span class="st"> </span>estimand[<span class="dv">1</span>]
)

<span class="co"># Run 25000 simulations</span>
<span class="kw">set.seed</span>(<span class="dv">25</span>)
dig &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/diagnose_design">diagnose_design</a></span>(
  classical_design, 
  <span class="dt">sims =</span> <span class="dv">25000</span>, 
  <span class="dt">diagnosands =</span> my_diagnosands, 
  <span class="dt">parallel =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<p>Our diagnosands can help us see if there is any bias. Note that the standard error of the diagnosands is a useful tool that let’s us know whether our estimated bias, or any other diagnosand, is simply an artifact of simulation noise or if it appears to be precisely estimated via simulation.</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th align="right">Diagnosand</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>True Variance</td>
<td align="right">0.07832</td>
</tr>
<tr class="even">
<td>Mean of Estimated Variance</td>
<td align="right">0.07849</td>
</tr>
<tr class="odd">
<td>Bias of Estimated Variance</td>
<td align="right">0.00017</td>
</tr>
<tr class="even">
<td>se(Bias of Estimated Variance)</td>
<td align="right">0.00010</td>
</tr>
</tbody>
</table>
<p>As we can see the bias is very close to zero and because the standard error is not much smaller than the bias, we can be reasonably certain that the only reason the bias is not exactly zero is due to simulation error. We can also see this visually, using a density plot of estimated variances with a line for the true variance.</p>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-9-1.png" width="480"></p>
<p>We can also show that the standard error is unbiased for the standard deviation of the sampling distribution of <span class="math inline">\(\beta\)</span> and that the coverage is appropriate.</p>
<table class="table">
<thead><tr class="header">
<th></th>
<th align="right">Diagnosand</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Bias of Standard Error</td>
<td align="right">-0.00116</td>
</tr>
<tr class="even">
<td>se(Bias of Standard Error)</td>
<td align="right">0.00123</td>
</tr>
<tr class="odd">
<td>Coverage Rate</td>
<td align="right">0.95164</td>
</tr>
<tr class="even">
<td>se(Coverage Rate)</td>
<td align="right">0.00126</td>
</tr>
</tbody>
</table>
</div>
<div id="heteroskedastic-errors-and-fixed-covariates" class="section level2">
<h2 class="hasAnchor">
<a href="#heteroskedastic-errors-and-fixed-covariates" class="anchor"></a>Heteroskedastic errors and fixed covariates</h2>
<p>Now let’s use the same fixed data set-up, but now let’s introduce heteroskedasticity. In this case, the variance of the errors is different across units (i.e. <span class="math inline">\(\sigma^2_i \neq \sigma^2_j\)</span> for some units <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>. If this variance of the errors is not independent of the regressors, the “classical” variance will be biased and inconsistent. Meanwhile, heteroskedastic-consistent variance estimators, such as the HC2 estimator, are consistent and normally less biased than the “classical” estimator. Let’s demonstrate this using <a href="declaredesign.org"><code>DeclareDesign</code></a>. First, let’s specify the variance of the errors to be strongly correlated with <span class="math inline">\(x\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat &lt;-<span class="st"> </span><span class="kw">fabricate</span>(
  dat,
  <span class="dt">noise_var =</span> <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x))<span class="op">^</span><span class="dv">2</span>
)
<span class="co"># Plot shows variance of errors increasing with x</span>
<span class="kw">plot</span>(dat<span class="op">$</span>x, dat<span class="op">$</span>noise_var, <span class="dt">xlab =</span> <span class="st">"x"</span>, <span class="dt">ylab =</span> <span class="st">"sigmasq_i"</span>)</code></pre></div>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-11-1.png" width="384"></p>
<p>Note that the general form of the true variance with fixed covariates is:</p>
<p><span class="math display">\[
\mathbb{V}[\widehat{\beta}] = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{\Phi} \mathbf{X} (\mathbf{X}^\top \mathbf{X})^{-1},
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\Phi}\)</span> is the variance covariance matrix of the errors, or <span class="math inline">\(\mathbf{\Phi} = \mathbb{E}[\epsilon\epsilon^\top]\)</span>. In the above case with homoskedasticity, we assumed <span class="math inline">\(\mathbf{\Phi} = \sigma^2 \mathbf{I}\)</span> and were able to simplify. Now, as in the standard set up for heteroskedasticity, we set <span class="math inline">\(\mathbf{\Phi}\)</span> to be a diagonal matrix where <code>noise_var</code>, the variance for each unit’s error, is on the diagonal. Using that error structure and the error for each unit, we can estimate the true variance.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Xmat &lt;-<span class="st"> </span><span class="kw">with</span>(dat, <span class="kw">cbind</span>(<span class="dv">1</span>, x))
XtX_inv &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(Xmat))
varb &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(XtX_inv, Xmat) <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(<span class="kw">with</span>(dat, noise_var)) <span class="op">%*%</span><span class="st"> </span>Xmat <span class="op">%*%</span><span class="st"> </span>XtX_inv
true_varb_het &lt;-<span class="st"> </span>varb[<span class="dv">2</span>, <span class="dv">2</span>]
true_varb_het</code></pre></div>
<pre><code>## [1] 0.1473923</code></pre>
<p>Now let’s use <a href="declaredesign.org"><code>DeclareDesign</code></a> to test whether HC2 is less biased in this example than classical standard errors. However, I will use another feature of <a href="declaredesign.org"><code>DeclareDesign</code></a> where I can create a design template. This allows me to easily pass different datasets (i.e., of different sizes) so that I can test the properties of the estimator across different datasets.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># This creates a template that takes some fixed data</span>
<span class="co"># that has x and noise_var. Then for that data, it creates</span>
<span class="co"># a single design that you can then simulate many times to get</span>
<span class="co"># the properties you are interested in</span>
fixed_dat_het_design_temp &lt;-<span class="st"> </span><span class="cf">function</span>(dat) {
  
  <span class="co"># Get true variance for this data</span>
  Xmat &lt;-<span class="st"> </span><span class="kw">with</span>(dat, <span class="kw">cbind</span>(<span class="dv">1</span>, x))
  XtX_inv &lt;-<span class="st"> </span><span class="kw">solve</span>(<span class="kw">crossprod</span>(Xmat))
  varb &lt;-<span class="st"> </span><span class="kw">tcrossprod</span>(XtX_inv, Xmat) <span class="op">%*%</span><span class="st"> </span><span class="kw">diag</span>(<span class="kw">with</span>(dat, noise_var)) <span class="op">%*%</span><span class="st"> </span>Xmat <span class="op">%*%</span><span class="st"> </span>XtX_inv
  true_varb_het &lt;-<span class="st"> </span>varb[<span class="dv">2</span>, <span class="dv">2</span>]
  
  <span class="co"># Population function now has heteroskedastic noise</span>
  simp_pop &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_population">declare_population</a></span>(
    <span class="dt">epsilon =</span> <span class="kw">rnorm</span>(N, <span class="dt">sd =</span> <span class="kw">sqrt</span>(noise_var)),
    <span class="dt">y =</span> x <span class="op">+</span><span class="st"> </span>epsilon
  )

  varb_het_estimand &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_estimand">declare_estimand</a></span>(<span class="dt">true_varb_het =</span> true_varb_het)

  <span class="co"># Now we declare the two estimators</span>
  lmc &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_estimator">declare_estimator</a></span>(
    y <span class="op">~</span><span class="st"> </span>x,
    <span class="dt">model =</span> estimatr<span class="op">::</span>lm_robust,
    <span class="dt">se_type =</span> <span class="st">"classical"</span>,
    <span class="dt">estimand =</span> varb_het_estimand,
    <span class="dt">coefficient_name =</span> <span class="st">"x"</span>,
    <span class="dt">label =</span> <span class="st">"classical"</span>
  )
  
  lmr_hc2 &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_estimator">declare_estimator</a></span>(
    y <span class="op">~</span><span class="st"> </span>x, 
    <span class="dt">model =</span> estimatr<span class="op">::</span>lm_robust, 
    <span class="dt">se_type =</span> <span class="st">"HC2"</span>,
    <span class="dt">estimand =</span> varb_het_estimand,
    <span class="dt">coefficient_name =</span> <span class="st">"x"</span>,
    <span class="dt">label =</span> <span class="st">"HC2"</span>
  )
  
  <span class="co"># We return the design so we can diagnose it</span>
  <span class="kw">return</span>(
    <span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/declare_design">declare_design</a></span>(
      dat,
      simp_pop,
      varb_het_estimand,
      lmc, 
      lmr_hc2
    )
  )
}</code></pre></div>
<p>So let’s use the same diagnosands as above to test the properties of our dataset with heteroskedasticity.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Create a design using our template and the data we have been using</span>
het_design &lt;-<span class="st"> </span><span class="kw">fixed_dat_het_design_temp</span>(dat)

dig_het &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/diagnose_design">diagnose_design</a></span>(
  het_design,
  <span class="dt">sims =</span> <span class="dv">10000</span>, 
  <span class="dt">diagnosands =</span> my_diagnosands,
  <span class="dt">parallel =</span> <span class="ot">TRUE</span>
)</code></pre></div>
<table class="table">
<thead><tr class="header">
<th></th>
<th align="right">Classical Est.</th>
<th align="right">HC2</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>True Variance</td>
<td align="right">0.14739</td>
<td align="right">0.14739</td>
</tr>
<tr class="even">
<td>Mean of Estimated Variance</td>
<td align="right">0.11249</td>
<td align="right">0.14624</td>
</tr>
<tr class="odd">
<td>Bias of Estimated Variance</td>
<td align="right">-0.03490</td>
<td align="right">-0.00115</td>
</tr>
<tr class="even">
<td>se(Bias of Estimated Variance)</td>
<td align="right">0.00027</td>
<td align="right">0.00072</td>
</tr>
<tr class="odd">
<td>Bias of Standard Error</td>
<td align="right">-0.04947</td>
<td align="right">-0.01035</td>
</tr>
<tr class="even">
<td>se(Bias of Standard Error)</td>
<td align="right">0.00249</td>
<td align="right">0.00254</td>
</tr>
<tr class="odd">
<td>Coverage Rate</td>
<td align="right">0.91670</td>
<td align="right">0.93700</td>
</tr>
<tr class="even">
<td>se(Coverage Rate)</td>
<td align="right">0.00250</td>
<td align="right">0.00217</td>
</tr>
</tbody>
</table>
<p>As you can see, the bias for the HC2 errors is much closer to zero, whereas the bias for the classical error is much larger, especially when compared to the standard error of the bias diagnosand. Let’s look how the bias change as the sample size changes.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Ns &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2500</span>, <span class="dv">5000</span>)
diags &lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">"list"</span>, <span class="kw">length</span>(Ns))

<span class="kw">set.seed</span>(<span class="dv">42</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_along</span>(Ns)) {
  <span class="co"># Generate ONE fixed dataset</span>
  dat &lt;-<span class="st"> </span><span class="kw">fabricate</span>(
    <span class="dt">N =</span> Ns[i],
    <span class="dt">x =</span> <span class="kw">rnorm</span>(N),
    <span class="dt">noise_var =</span> <span class="dv">1</span> <span class="op">+</span><span class="st"> </span>(x <span class="op">-</span><span class="st"> </span><span class="kw">min</span>(x))<span class="op">^</span><span class="dv">2</span>
  )
  des &lt;-<span class="st"> </span><span class="kw">fixed_dat_het_design_temp</span>(dat)
  diags[[i]] &lt;-<span class="st"> </span><span class="kw"><a href="http://www.rdocumentation.org/packages/DeclareDesign/topics/diagnose_design">diagnose_design</a></span>(
    des,
    <span class="dt">sims =</span> <span class="dv">10000</span>, 
    <span class="dt">diagnosands =</span> my_diagnosands
  )<span class="op">$</span>diagnosands
  diags[[i]]<span class="op">$</span>N &lt;-<span class="st"> </span>Ns[i]
}</code></pre></div>
<p><img src="simulations-ols-variance_files/figure-html/unnamed-chunk-17-1.png" width="480"></p>
<p>As you can see, the HC2 variance tends to be conservative and is consistent, converging to the true value as the sample size increases, while the classical error is biased downwards even as the sample sizes increases.</p>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#homoskedastic-errors-and-fixed-covariates">Homoskedastic errors and fixed covariates</a></li>
      <li><a href="#heteroskedastic-errors-and-fixed-covariates">Heteroskedastic errors and fixed covariates</a></li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright" style="flex:3;">
  <p>Developed by Graeme Blair, Jasper Cooper, Alexander Coppock, Macartan Humphreys, Luke Sonnet, Neal Fultz.</p>
  <p>Code is licensed under <a href="https://opensource.org/licenses/mit-license.php">MIT</a> license.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://hadley.github.io/pkgdown/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
